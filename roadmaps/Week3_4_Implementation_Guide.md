# Week 3-4: ìŠ¤ë§ˆíŠ¸ ê²¬ì  ì‹œìŠ¤í…œ & ë¬¸ì„œ AI

## ğŸ¯ **Week 3 ëª©í‘œ**
AI ê¸°ë°˜ **ìŠ¤ë§ˆíŠ¸ ê²¬ì  ì‹œìŠ¤í…œ** êµ¬ì¶• (7/4 - 7/10)

## ğŸ¯ **Week 4 ëª©í‘œ**
**ë¬¸ì„œ ì§€ëŠ¥ ê²€ìƒ‰ ì—”ì§„** êµ¬ì¶• ë° ì „ì²´ ì‹œìŠ¤í…œ ì™„ì„± (7/11 - 7/13)

---

## ğŸ“‹ **Week 3: ìŠ¤ë§ˆíŠ¸ ê²¬ì  ì‹œìŠ¤í…œ**

### **Day 15-16: ë°ì´í„° ë¶„ì„ & ëª¨ë¸ë§**

```python
# backend/ai-service/estimation/project_analyzer.py
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import pandas as pd
import os

class ProjectAnalyzer:
    def __init__(self):
        self.llm = ChatOpenAI(
            temperature=0.3,
            model="gpt-4",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )

    async def analyze_project_requirements(self, requirements: dict):
        """í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„"""
        analysis_prompt = ChatPromptTemplate.from_template("""
        ë‹¤ìŒ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì œí’ˆ ì¡°í•©ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”:
        
        í”„ë¡œì íŠ¸ ì •ë³´:
        - ìš©ë„: {purpose}
        - ë©´ì : {area} mÂ²
        - í™˜ê²½: {environment}
        - ì˜ˆì‚°: {budget}
        
        ë¦°ì½”ë¦¬ì•„ ì œí’ˆêµ°:
        - ë¦°ì½”íŠ¸: ë°”ë‹¥ ì½”íŒ…ì¬ (ë°©ìˆ˜, ë‚´êµ¬ì„±)
        - ë¦°í•˜ë“œ: ê²½í™”ì œ (ê°•ë„ ì¦ì§„)
        - ë¦°ì”°: ì‹¤ë§ì œ (ë°©ìˆ˜, ë°€ë´‰)
        
        ì¶”ì²œ ì œí’ˆ ì¡°í•©ê³¼ ìˆ˜ëŸ‰ì„ JSON í˜•íƒœë¡œ ë°˜í™˜:
        """)
        
        result = await self.llm.ainvoke({
            "purpose": requirements.get("purpose"),
            "area": requirements.get("area"),
            "environment": requirements.get("environment"),
            "budget": requirements.get("budget")
        })
        
        return result.content

class EstimationEngine:
    def __init__(self):
        self.analyzer = ProjectAnalyzer()
        
    async def generate_estimate(self, project_data: dict):
        """ê²¬ì ì„œ ìë™ ìƒì„±"""
        # 1. í”„ë¡œì íŠ¸ ë¶„ì„
        analysis = await self.analyzer.analyze_project_requirements(project_data)
        
        # 2. ì œí’ˆ ë§¤ì¹­ ë° ê°€ê²© ê³„ì‚°
        products = self._match_products(analysis)
        total_cost = self._calculate_cost(products)
        
        # 3. ê²¬ì ì„œ ë°ì´í„° êµ¬ì„±
        estimate = {
            "project_id": project_data.get("id"),
            "products": products,
            "total_cost": total_cost,
            "delivery_time": self._estimate_delivery_time(products),
            "validity_period": 30  # 30ì¼
        }
        
        return estimate
    
    def _match_products(self, analysis):
        """ì œí’ˆ ë§¤ì¹­"""
        # ì‹¤ì œ ì œí’ˆ DBì—ì„œ ë§¤ì¹­í•˜ëŠ” ë¡œì§
        return [
            {"name": "ë¦°ì½”íŠ¸", "quantity": 10, "unit_price": 50000},
            {"name": "ë¦°í•˜ë“œ", "quantity": 5, "unit_price": 30000}
        ]
    
    def _calculate_cost(self, products):
        """ë¹„ìš© ê³„ì‚°"""
        return sum(p["quantity"] * p["unit_price"] for p in products)
    
    def _estimate_delivery_time(self, products):
        """ë°°ì†¡ ì‹œê°„ ì˜ˆì¸¡"""
        return "3-5 ì˜ì—…ì¼"
```

### **Day 17-18: ê²¬ì  ì‹œìŠ¤í…œ ê°œë°œ**

```python
# backend/ai-service/api/estimation_endpoints.py
from fastapi import APIRouter, HTTPException
from estimation.estimation_engine import EstimationEngine
from pydantic import BaseModel

router = APIRouter(prefix="/api/estimation", tags=["Smart Estimation"])

class EstimationRequest(BaseModel):
    purpose: str
    area: float
    environment: str
    budget: int
    contact_info: dict

estimation_engine = EstimationEngine()

@router.post("/generate")
async def generate_estimate(request: EstimationRequest):
    """AI ê²¬ì ì„œ ìƒì„±"""
    try:
        project_data = request.dict()
        estimate = await estimation_engine.generate_estimate(project_data)
        
        return {
            "success": True,
            "estimate": estimate,
            "generated_at": "2025-07-08T10:30:00Z"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/template/{project_type}")
async def get_estimate_template(project_type: str):
    """ê²¬ì ì„œ í…œí”Œë¦¿ ì¡°íšŒ"""
    templates = {
        "warehouse": {
            "recommended_products": ["ë¦°ì½”íŠ¸", "ë¦°í•˜ë“œ"],
            "typical_area": "1000-5000 mÂ²",
            "estimated_cost_per_sqm": 15000
        }
    }
    return templates.get(project_type, templates["warehouse"])
```

### **Day 19-21: PDF ê²¬ì ì„œ ìƒì„±**

```python
# backend/ai-service/pdf/pdf_generator.py
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfutils
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
import io

class PDFEstimateGenerator:
    def __init__(self):
        # í•œê¸€ í°íŠ¸ ë“±ë¡ (í•„ìš”ì‹œ)
        # pdfmetrics.registerFont(TTFont('Korean', 'NanumGothic.ttf'))
        pass
    
    def generate_estimate_pdf(self, estimate_data: dict) -> bytes:
        """ê²¬ì ì„œ PDF ìƒì„±"""
        buffer = io.BytesIO()
        p = canvas.Canvas(buffer, pagesize=A4)
        
        # PDF ë‚´ìš© ì‘ì„±
        self._draw_header(p)
        self._draw_estimate_details(p, estimate_data)
        self._draw_footer(p)
        
        p.save()
        buffer.seek(0)
        return buffer.getvalue()
    
    def _draw_header(self, canvas):
        """í—¤ë” ê·¸ë¦¬ê¸°"""
        canvas.setFont("Helvetica-Bold", 24)
        canvas.drawString(50, 750, "RinKorea Estimate")
        
    def _draw_estimate_details(self, canvas, data):
        """ê²¬ì  ë‚´ìš© ê·¸ë¦¬ê¸°"""
        y_position = 700
        for product in data.get("products", []):
            text = f"{product['name']}: {product['quantity']} x {product['unit_price']:,}ì›"
            canvas.drawString(50, y_position, text)
            y_position -= 30
    
    def _draw_footer(self, canvas):
        """í‘¸í„° ê·¸ë¦¬ê¸°"""
        canvas.drawString(50, 50, "ë¦°ì½”ë¦¬ì•„ - ê³ í’ˆì§ˆ ê±´ì„¤ ì†Œì¬")
```

---

## ğŸ“‹ **Week 4: ë¬¸ì„œ AI & ìµœì¢… ì™„ì„±**

### **Day 22: ë¬¸ì„œ ì²˜ë¦¬ AI**

```python
# backend/ai-service/documents/document_processor.py
import pytesseract
from PIL import Image
import PyPDF2
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
import io

class DocumentProcessor:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    async def process_pdf(self, pdf_bytes: bytes) -> list:
        """PDF ë¬¸ì„œ ì²˜ë¦¬"""
        text_content = self._extract_pdf_text(pdf_bytes)
        chunks = self.text_splitter.split_text(text_content)
        
        # ì„ë² ë”© ìƒì„±
        embeddings = await self.embeddings.aembed_documents(chunks)
        
        return [
            {"text": chunk, "embedding": emb}
            for chunk, emb in zip(chunks, embeddings)
        ]
    
    def _extract_pdf_text(self, pdf_bytes: bytes) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text
    
    async def process_image(self, image_bytes: bytes) -> str:
        """ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        image = Image.open(io.BytesIO(image_bytes))
        text = pytesseract.image_to_string(image, lang='kor+eng')
        return text

class SemanticSearchEngine:
    def __init__(self):
        self.vector_store = None  # ChromaDB ì—°ê²°
    
    async def semantic_search(self, query: str, top_k: int = 5):
        """ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰"""
        # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        results = self.vector_store.similarity_search(query, k=top_k)
        return results
    
    async def document_qa(self, question: str, document_context: str):
        """ë¬¸ì„œ ê¸°ë°˜ Q&A"""
        from langchain_openai import ChatOpenAI
        
        llm = ChatOpenAI(model="gpt-4")
        prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
        
        ë¬¸ì„œ: {document_context}
        ì§ˆë¬¸: {question}
        
        ë‹µë³€:
        """
        
        response = await llm.ainvoke(prompt)
        return response.content
```

### **Day 23: í†µí•© & í…ŒìŠ¤íŠ¸**

```python
# backend/ai-service/integration/system_integrator.py
from ai.chat_chain import ChatChain
from workflows.executor import WorkflowExecutor
from estimation.estimation_engine import EstimationEngine
from documents.document_processor import DocumentProcessor

class AISystemIntegrator:
    def __init__(self):
        self.chatbot = ChatChain()
        self.qna_workflow = WorkflowExecutor()
        self.estimation_engine = EstimationEngine()
        self.document_processor = DocumentProcessor()
    
    async def unified_ai_service(self, request_type: str, data: dict):
        """í†µí•© AI ì„œë¹„ìŠ¤"""
        if request_type == "chat":
            return await self.chatbot.get_response(data["message"])
        
        elif request_type == "qna_automation":
            return await self.qna_workflow.process_inquiry(data)
        
        elif request_type == "estimation":
            return await self.estimation_engine.generate_estimate(data)
        
        elif request_type == "document_search":
            return await self.document_processor.semantic_search(data["query"])
        
        else:
            return {"error": "Unknown request type"}

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
class PerformanceTester:
    async def run_load_test(self):
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
        import asyncio
        import time
        
        tasks = []
        start_time = time.time()
        
        # 100ê°œ ë™ì‹œ ìš”ì²­
        for i in range(100):
            task = self._test_request(f"í…ŒìŠ¤íŠ¸ ë¬¸ì˜ {i}")
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        
        return {
            "total_requests": 100,
            "total_time": end_time - start_time,
            "average_response_time": (end_time - start_time) / 100,
            "success_rate": sum(1 for r in results if r.get("success")) / 100
        }
```

### **Day 24: ë¬¸ì„œí™” & í¬íŠ¸í´ë¦¬ì˜¤ ì™„ì„±**

```markdown
# ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±

## ğŸ“ GitHub Repository êµ¬ì¡°
```
rinkorea-ai-platform/
â”œâ”€â”€ backend/ai-service/          # Python AI ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ ai/                      # ì±—ë´‡ ì—”ì§„
â”‚   â”œâ”€â”€ workflows/               # LangGraph ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ estimation/              # ê²¬ì  ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ documents/               # ë¬¸ì„œ AI
â”‚   â”œâ”€â”€ api/                     # FastAPI ì—”ë“œí¬ì¸íŠ¸
â”‚   â””â”€â”€ tests/                   # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ frontend/                    # Next.js í”„ë¡ íŠ¸ì—”ë“œ
â”œâ”€â”€ docker/                      # Docker ì„¤ì •
â”œâ”€â”€ docs/                        # ê¸°ìˆ  ë¬¸ì„œ
â””â”€â”€ README.md                    # ë°ëª¨ ê°€ì´ë“œ
```

## ğŸ“Š ì„±ê³¼ ì§€í‘œ ëŒ€ì‹œë³´ë“œ
- ì±—ë´‡ ì‘ë‹µ ì •í™•ë„: **87%**
- Q&A ìë™ ì²˜ë¦¬ìœ¨: **73%**  
- ê²¬ì  ìƒì„± ì‹œê°„: **í‰ê·  45ì´ˆ**
- ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬: **150ëª…+**

## ğŸš€ ë¼ì´ë¸Œ ë°ëª¨ ì‚¬ì´íŠ¸
- URL: https://rinkorea-ai.vercel.app
- ê´€ë¦¬ì íŒ¨ë„: /admin
- API ë¬¸ì„œ: /docs
```

---

## ğŸ† **ìµœì¢… ì™„ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **Week 3: ê²¬ì  ì‹œìŠ¤í…œ**
- [ ] í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„ AI
- [ ] ì œí’ˆ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- [ ] ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸
- [ ] PDF ê²¬ì ì„œ ìë™ ìƒì„±
- [ ] ê²¬ì  íˆìŠ¤í† ë¦¬ ê´€ë¦¬

### **Week 4: ë¬¸ì„œ AI & í†µí•©**
- [ ] PDF/ì´ë¯¸ì§€ OCR ì²˜ë¦¬
- [ ] ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì—”ì§„
- [ ] ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í†µí•©
- [ ] ì„±ëŠ¥ ìµœì í™” & í…ŒìŠ¤íŠ¸

### **í¬íŠ¸í´ë¦¬ì˜¤ ì™„ì„±**
- [ ] GitHub ë¦¬í¬ì§€í† ë¦¬ ì •ë¦¬
- [ ] ë¼ì´ë¸Œ ë°ëª¨ ì‚¬ì´íŠ¸ ë°°í¬
- [ ] ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±
- [ ] ë°œí‘œ ìë£Œ ì¤€ë¹„
- [ ] ì„±ê³¼ ì§€í‘œ ì •ë¦¬

**ìµœì¢… ê²°ê³¼ë¬¼:**
ğŸ¯ **ì™„ì„±ë„ ë†’ì€ AI í”Œë«í¼**
ğŸ¯ **ì‹¤ë¬´ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ**
ğŸ¯ **MIDAS ìš”êµ¬ì‚¬í•­ 100% ì¶©ì¡±**
ğŸ¯ **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**

ì´ ê³„íšìœ¼ë¡œ **MIDASì—ì„œ ì›í•˜ëŠ” ëª¨ë“  ê¸°ìˆ  ìŠ¤íƒê³¼ ì‹¤ë¬´ ê²½í—˜**ì„ ì™„ë²½í•˜ê²Œ ê°–ì¶˜ í¬íŠ¸í´ë¦¬ì˜¤ê°€ ì™„ì„±ë©ë‹ˆë‹¤! ğŸš€ 