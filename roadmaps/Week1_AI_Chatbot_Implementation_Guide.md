# Week 1: AI ì±—ë´‡ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ¯ **ëª©í‘œ**
ë¦°ì½”ë¦¬ì•„ ì œí’ˆ ì •ë³´ë¥¼ í™œìš©í•œ **ì‹¤ì‹œê°„ AI ìƒë‹´ ì±—ë´‡** êµ¬ì¶•

---

## ğŸ“‹ **Day 1-2: ì¸í”„ë¼ & ê¸°ë³¸ ì„¤ì •**

### **1. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±**

```bash
# AI ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir backend/ai-service
cd backend/ai-service

# Python ê°€ìƒí™˜ê²½ ì„¤ì •
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install langchain langchain-openai openai python-dotenv fastapi uvicorn websockets
```

### **2. í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±**

```python
# backend/ai-service/.env
OPENAI_API_KEY=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
SUPABASE_URL=https://fpyqjvnpduwifxgnbrck.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZweXFqdm5wZHV3aWZ4Z25icmNrIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDk1NDA0MDQsImV4cCI6MjA2NTExNjQwNH0.Uqn7ajeRHEqMl7gbPtOYHKd1ZhUb6xiMTZsK4QMxtfU
PINECONE_API_KEY=pcsk_4AQeoW_T5yG4j6JcG2kbvQZjTsrBg5HzyYofmLZUixjrCz3gG4s4sBWVN6TZ819BzNzCY8
ENVIRONMENT=development
LOG_LEVEL=INFO
```

### **3. FastAPI ê¸°ë³¸ êµ¬ì¡°**

```python
# backend/ai-service/main.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import os
import logging

load_dotenv()

app = FastAPI(title="RinKorea AI Service", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # í”„ë¡ íŠ¸ì—”ë“œ URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=getattr(logging, os.getenv("LOG_LEVEL", "INFO")))
logger = logging.getLogger(__name__)

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "RinKorea AI"}

# WebSocket ì—°ê²° ê´€ë¦¬ì
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

manager = ConnectionManager()

@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            # ì—¬ê¸°ì— AI ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
            response = f"Echo: {data}"
            await manager.send_personal_message(response, websocket)
    except WebSocketDisconnect:
        manager.disconnect(websocket)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### **4. í”„ë¡ íŠ¸ì—”ë“œ ì±—ë´‡ UI ì»´í¬ë„ŒíŠ¸**

```typescript
// src/components/ai/ChatBot.tsx
import React, { useState, useEffect, useRef } from 'react';
import { Send, Bot, User } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';

interface Message {
  id: string;
  content: string;
  sender: 'user' | 'bot';
  timestamp: Date;
}

const ChatBot: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [isConnected, setIsConnected] = useState(false);
  const [isTyping, setIsTyping] = useState(false);
  const websocket = useRef<WebSocket | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    // WebSocket ì—°ê²°
    websocket.current = new WebSocket('ws://localhost:8000/ws/chat');
    
    websocket.current.onopen = () => {
      setIsConnected(true);
      addMessage('ì•ˆë…•í•˜ì„¸ìš”! ë¦°ì½”ë¦¬ì•„ AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ì œí’ˆì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”.', 'bot');
    };

    websocket.current.onmessage = (event) => {
      setIsTyping(false);
      addMessage(event.data, 'bot');
    };

    websocket.current.onclose = () => {
      setIsConnected(false);
    };

    return () => {
      websocket.current?.close();
    };
  }, []);

  const addMessage = (content: string, sender: 'user' | 'bot') => {
    const newMessage: Message = {
      id: Date.now().toString(),
      content,
      sender,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, newMessage]);
  };

  const sendMessage = () => {
    if (!inputValue.trim() || !websocket.current) return;

    addMessage(inputValue, 'user');
    setIsTyping(true);
    websocket.current.send(inputValue);
    setInputValue('');
  };

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  return (
    <div className="fixed bottom-4 right-4 w-80 h-96 bg-white rounded-lg shadow-xl border border-gray-200 flex flex-col">
      {/* í—¤ë” */}
      <div className="bg-blue-600 text-white p-3 rounded-t-lg flex items-center">
        <Bot className="w-5 h-5 mr-2" />
        <span className="font-semibold">AI ìƒë‹´ì›</span>
        <div className={`ml-auto w-2 h-2 rounded-full ${isConnected ? 'bg-green-400' : 'bg-red-400'}`} />
      </div>

      {/* ë©”ì‹œì§€ ì˜ì—­ */}
      <div className="flex-1 overflow-y-auto p-3 space-y-3">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.sender === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-[80%] rounded-lg p-2 ${
                message.sender === 'user'
                  ? 'bg-blue-600 text-white'
                  : 'bg-gray-100 text-gray-800'
              }`}
            >
              <div className="flex items-start space-x-2">
                {message.sender === 'bot' && <Bot className="w-4 h-4 mt-1 text-blue-600" />}
                {message.sender === 'user' && <User className="w-4 h-4 mt-1" />}
                <span className="text-sm">{message.content}</span>
              </div>
            </div>
          </div>
        ))}
        
        {isTyping && (
          <div className="flex justify-start">
            <div className="bg-gray-100 rounded-lg p-2">
              <div className="flex items-center space-x-1">
                <Bot className="w-4 h-4 text-blue-600" />
                <span className="text-sm text-gray-600">ì…ë ¥ ì¤‘...</span>
                <div className="flex space-x-1">
                  <div className="w-1 h-1 bg-gray-400 rounded-full animate-bounce" />
                  <div className="w-1 h-1 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }} />
                  <div className="w-1 h-1 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }} />
                </div>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* ì…ë ¥ ì˜ì—­ */}
      <div className="p-3 border-t border-gray-200">
        <div className="flex space-x-2">
          <Input
            value={inputValue}
            onChange={(e) => setInputValue(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
            placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
            disabled={!isConnected}
            className="flex-1"
          />
          <Button 
            onClick={sendMessage} 
            disabled={!isConnected || !inputValue.trim()}
            size="sm"
          >
            <Send className="w-4 h-4" />
          </Button>
        </div>
      </div>
    </div>
  );
};

export default ChatBot;
```

---

## ğŸ“‹ **Day 3-4: RAG ì‹œìŠ¤í…œ êµ¬ì¶•**

### **1. Vector Database ì„¤ì •**

```python
# backend/ai-service/database/vector_store.py
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
import os
from typing import List

class VectorStore:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.persist_directory = "./chroma_db"
        self.vector_store = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )

    def initialize_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        self.vector_store = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings
        )

    def add_documents(self, documents: List[Document]):
        """ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€"""
        if not self.vector_store:
            self.initialize_store()
        
        # ë¬¸ì„œ ì²­í‚¹
        texts = self.text_splitter.split_documents(documents)
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        self.vector_store.add_documents(texts)
        self.vector_store.persist()

    def similarity_search(self, query: str, k: int = 4):
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.vector_store:
            self.initialize_store()
        
        return self.vector_store.similarity_search(query, k=k)

    def similarity_search_with_score(self, query: str, k: int = 4):
        """ì ìˆ˜ì™€ í•¨ê»˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.vector_store:
            self.initialize_store()
        
        return self.vector_store.similarity_search_with_score(query, k=k)
```

### **2. ì œí’ˆ ë°ì´í„° ë¡œë”**

```python
# backend/ai-service/data/product_loader.py
from langchain.schema import Document
from typing import List
import asyncio
import aiohttp
import os

class ProductDataLoader:
    def __init__(self):
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_ANON_KEY")

    async def load_products(self) -> List[Document]:
        """Supabaseì—ì„œ ì œí’ˆ ë°ì´í„° ë¡œë“œ"""
        async with aiohttp.ClientSession() as session:
            headers = {
                "apikey": self.supabase_key,
                "Authorization": f"Bearer {self.supabase_key}",
                "Content-Type": "application/json"
            }
            
            async with session.get(
                f"{self.supabase_url}/rest/v1/product_introductions",
                headers=headers
            ) as response:
                products = await response.json()

        documents = []
        for product in products:
            # ì œí’ˆ ì •ë³´ë¥¼ Documentë¡œ ë³€í™˜
            content = f"""
            ì œí’ˆëª…: {product['name']}
            ì„¤ëª…: {product['description']}
            íŠ¹ì§•: {', '.join(product.get('features', []))}
            ì¹´í…Œê³ ë¦¬: {product.get('category', 'ì¼ë°˜')}
            """
            
            metadata = {
                "source": "product_db",
                "product_id": product['id'],
                "product_name": product['name'],
                "type": "product_info"
            }
            
            documents.append(Document(page_content=content, metadata=metadata))

        return documents

    async def load_projects(self) -> List[Document]:
        """í”„ë¡œì íŠ¸ ë°ì´í„° ë¡œë“œ"""
        async with aiohttp.ClientSession() as session:
            headers = {
                "apikey": self.supabase_key,
                "Authorization": f"Bearer {self.supabase_key}",
                "Content-Type": "application/json"
            }
            
            async with session.get(
                f"{self.supabase_url}/rest/v1/projects",
                headers=headers
            ) as response:
                projects = await response.json()

        documents = []
        for project in projects:
            content = f"""
            í”„ë¡œì íŠ¸ëª…: {project['title']}
            ì„¤ëª…: {project['description']}
            ìœ„ì¹˜: {project.get('location', '')}
            ì¹´í…Œê³ ë¦¬: {project.get('category', '')}
            ì™„ë£Œì¼: {project.get('completion_date', '')}
            """
            
            metadata = {
                "source": "project_db",
                "project_id": project['id'],
                "project_name": project['title'],
                "type": "project_case"
            }
            
            documents.append(Document(page_content=content, metadata=metadata))

        return documents
```

### **3. ì´ˆê¸° ë°ì´í„° ì„ë² ë”©**

```python
# backend/ai-service/scripts/setup_vector_db.py
import asyncio
from database.vector_store import VectorStore
from data.product_loader import ProductDataLoader

async def setup_vector_database():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸° ì„¤ì •"""
    print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹œì‘...")
    
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    loader = ProductDataLoader()
    vector_store = VectorStore()
    
    try:
        # ì œí’ˆ ë°ì´í„° ë¡œë“œ
        print("ì œí’ˆ ë°ì´í„° ë¡œë”© ì¤‘...")
        product_docs = await loader.load_products()
        print(f"ì œí’ˆ ë¬¸ì„œ {len(product_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        
        # í”„ë¡œì íŠ¸ ë°ì´í„° ë¡œë“œ
        print("í”„ë¡œì íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
        project_docs = await loader.load_projects()
        print(f"í”„ë¡œì íŠ¸ ë¬¸ì„œ {len(project_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        print("ë²¡í„°í™” ë° ì €ì¥ ì¤‘...")
        all_docs = product_docs + project_docs
        vector_store.add_documents(all_docs)
        
        print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ!")
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        test_results = vector_store.similarity_search("ë°©ìˆ˜ ì œí’ˆ", k=3)
        print("\ní…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼:")
        for i, doc in enumerate(test_results, 1):
            print(f"{i}. {doc.page_content[:100]}...")
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    asyncio.run(setup_vector_database())
```

---

## ğŸ“‹ **Day 5-7: ì±—ë´‡ ì™„ì„±**

### **1. LangChain ëŒ€í™” ì²´ì¸**

```python
# backend/ai-service/ai/chat_chain.py
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.schema import StrOutputParser
from database.vector_store import VectorStore
import os

class ChatChain:
    def __init__(self):
        self.llm = ChatOpenAI(
            temperature=0.7,
            model="gpt-4",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.vector_store = VectorStore()
        self.vector_store.initialize_store()
        
        # ë©”ëª¨ë¦¬ ì„¤ì • (ìµœê·¼ 10ê°œ ëŒ€í™” ê¸°ì–µ)
        self.memory = ConversationBufferWindowMemory(
            k=10,
            memory_key="chat_history",
            return_messages=True
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ë¦°ì½”ë¦¬ì•„ì˜ ì „ë¬¸ AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ì‘ë‹µí•˜ì„¸ìš”:

1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
2. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
3. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ ë§í•˜ê³ , ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œí•˜ì„¸ìš”
4. ì œí’ˆ ì¶”ì²œ ì‹œì—ëŠ” ê³ ê°ì˜ êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì„ ë¨¼ì € íŒŒì•…í•˜ì„¸ìš”
5. ì•ˆì „í•˜ê³  í’ˆì§ˆ ì¢‹ì€ ì œí’ˆ ì‚¬ìš©ì„ ìœ„í•œ ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”

ì»¨í…ìŠ¤íŠ¸ ì •ë³´:
{context}

í˜„ì¬ ëŒ€í™”ì—ì„œ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}")
        ])

    def get_relevant_context(self, question: str) -> str:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        try:
            docs = self.vector_store.similarity_search(question, k=4)
            context = "\n\n".join([doc.page_content for doc in docs])
            return context
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return ""

    async def get_response(self, question: str) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        try:
            # ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            context = self.get_relevant_context(question)
            
            # ì²´ì¸ ì‹¤í–‰
            chain = (
                {
                    "context": RunnableLambda(lambda x: context),
                    "question": RunnablePassthrough(),
                    "chat_history": RunnableLambda(lambda x: self.memory.chat_memory.messages)
                }
                | self.prompt
                | self.llm
                | StrOutputParser()
            )
            
            response = await chain.ainvoke(question)
            
            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            self.memory.chat_memory.add_user_message(question)
            self.memory.chat_memory.add_ai_message(response)
            
            return response
            
        except Exception as e:
            print(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def clear_history(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.memory.clear()
```

### **2. WebSocket í•¸ë“¤ëŸ¬ ì—…ë°ì´íŠ¸**

```python
# backend/ai-service/main.py ì—…ë°ì´íŠ¸
from ai.chat_chain import ChatChain
import json

# ì±— ì²´ì¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chat_chain = ChatChain()

# WebSocket ì—°ê²°ë³„ ì„¸ì…˜ ê´€ë¦¬
user_sessions = {}

@app.websocket("/ws/chat/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    await manager.connect(websocket)
    
    # ìƒˆ ì„¸ì…˜ì´ë©´ ChatChain ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    if session_id not in user_sessions:
        user_sessions[session_id] = ChatChain()
    
    try:
        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            user_message = message_data.get("message", "")
            message_type = message_data.get("type", "text")
            
            if message_type == "clear":
                # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
                user_sessions[session_id].clear_history()
                response = "ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                # AI ì‘ë‹µ ìƒì„±
                response = await user_sessions[session_id].get_response(user_message)
            
            # ì‘ë‹µ ì „ì†¡
            await manager.send_personal_message(
                json.dumps({
                    "message": response,
                    "type": "bot_response",
                    "timestamp": datetime.utcnow().isoformat()
                }),
                websocket
            )
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        # ì„¸ì…˜ ì •ë¦¬ (ì„ íƒì )
        if session_id in user_sessions:
            del user_sessions[session_id]
```

### **3. ë‹¤êµ­ì–´ ì§€ì›**

```python
# backend/ai-service/ai/translator.py
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import os

class Translator:
    def __init__(self):
        self.llm = ChatOpenAI(
            temperature=0.3,
            model="gpt-3.5-turbo",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        self.translation_prompt = ChatPromptTemplate.from_template("""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {target_language}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. 
        ê±´ì„¤/í™”í•™ ì œí’ˆ ê´€ë ¨ ì „ë¬¸ ìš©ì–´ëŠ” ì •í™•í•˜ê²Œ ë²ˆì—­í•˜ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì›ë¬¸: {text}
        
        ë²ˆì—­:
        """)

    async def translate(self, text: str, target_language: str) -> str:
        """í…ìŠ¤íŠ¸ ë²ˆì—­"""
        try:
            chain = self.translation_prompt | self.llm
            result = await chain.ainvoke({
                "text": text,
                "target_language": target_language
            })
            return result.content
        except Exception as e:
            print(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return text

    async def detect_language(self, text: str) -> str:
        """ì–¸ì–´ ê°ì§€"""
        detection_prompt = ChatPromptTemplate.from_template("""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , ì–¸ì–´ ì½”ë“œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
        - í•œêµ­ì–´: ko
        - ì˜ì–´: en  
        - ì¤‘êµ­ì–´: zh
        - ì¸ë„ë„¤ì‹œì•„ì–´: id
        
        í…ìŠ¤íŠ¸: {text}
        
        ì–¸ì–´ ì½”ë“œ:
        """)
        
        try:
            chain = detection_prompt | self.llm
            result = await chain.ainvoke({"text": text})
            return result.content.strip().lower()
        except Exception as e:
            print(f"ì–¸ì–´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return "ko"  # ê¸°ë³¸ê°’ í•œêµ­ì–´
```

### **4. ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸**

```bash
# backend/ai-service/run.py
import uvicorn
import os
from dotenv import load_dotenv

load_dotenv()

if __name__ == "__main__":
    # ë²¡í„° DB ì´ˆê¸° ì„¤ì • (ìµœì´ˆ ì‹¤í–‰ì‹œì—ë§Œ)
    import asyncio
    from scripts.setup_vector_db import setup_vector_database
    
    print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸ ì¤‘...")
    if not os.path.exists("./chroma_db"):
        print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
        asyncio.run(setup_vector_database())
    
    # ì„œë²„ ì‹¤í–‰
    print("AI ì„œë¹„ìŠ¤ ì‹œì‘...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
```

---

## ğŸš€ **ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸**

### **1. ë°±ì—”ë“œ ì‹¤í–‰**
```bash
cd backend/ai-service
python run.py
```

### **2. í”„ë¡ íŠ¸ì—”ë“œì— ì±—ë´‡ ì¶”ê°€**
```typescript
// src/app/layout.tsxì— ì¶”ê°€
import ChatBot from '@/components/ai/ChatBot';

export default function Layout({ children }: { children: React.ReactNode }) {
  return (
    <html lang="ko">
      <body>
        {children}
        <ChatBot />
      </body>
    </html>
  );
}
```

### **3. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**
- âœ… "ë¦°ì½”íŠ¸ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
- âœ… "ë°©ìˆ˜ ì œí’ˆ ì¶”ì²œí•´ì£¼ì„¸ìš”"  
- âœ… "ê²¬ì ì„ ë°›ê³  ì‹¶ì–´ìš”"
- âœ… "English please" (ë‹¤êµ­ì–´ í…ŒìŠ¤íŠ¸)

---

## ğŸ“Š **Week 1 ì™„ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸**

- [ ] FastAPI ê¸°ë³¸ ì„œë²„ êµ¬ë™
- [ ] WebSocket ì‹¤ì‹œê°„ ì±„íŒ…
- [ ] LangChain + GPT-4 ì—°ë™
- [ ] Vector DB (Chroma) êµ¬ì¶•
- [ ] ì œí’ˆ ë°ì´í„° RAG ê²€ìƒ‰
- [ ] ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬
- [ ] ë‹¤êµ­ì–´ ë²ˆì—­ ê¸°ëŠ¥
- [ ] ë°˜ì‘í˜• ì±„íŒ… UI
- [ ] ì—ëŸ¬ í•¸ë“¤ë§
- [ ] ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

**Week 1 ëª©í‘œ ë‹¬ì„± ì‹œ ì–»ëŠ” ê²ƒ:**
âœ… ì‹¤ì‹œê°„ AI ìƒë‹´ ì±—ë´‡ í”„ë¡œí† íƒ€ì…  
âœ… LangChain ì‹¤ë¬´ ê²½í—˜  
âœ… Vector DB êµ¬ì¶• ë…¸í•˜ìš°  
âœ… WebSocket ì‹¤ì‹œê°„ í†µì‹ 

ë‹¤ìŒ ì£¼ì°¨ì—ì„œëŠ” ì´ ì±—ë´‡ì„ ê¸°ë°˜ìœ¼ë¡œ **LangGraph ì›Œí¬í”Œë¡œìš°**ë¥¼ êµ¬ì¶•í•  ì˜ˆì •ì…ë‹ˆë‹¤! ğŸš€ 